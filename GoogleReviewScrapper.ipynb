{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ab835ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "GM_WEBPAGE = 'https://www.google.com/maps/'\n",
    "MAX_WAIT = 15\n",
    "MAX_RETRY = 5\n",
    "MAX_SCROLLS = 40\n",
    "\n",
    "class GoogleMapsScraper:\n",
    "\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "        self.driver = self.__getDriver()\n",
    "        self.logger = self.__getLogger()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def sortBy(self, url, ind):\n",
    "\n",
    "        self.driver.get(url)\n",
    "        self.__clickOnCookieAgreement()\n",
    "\n",
    "        wait = WebDriverWait(self.driver, MAX_WAIT)\n",
    "\n",
    "        # open dropdown menu\n",
    "        clicked = False\n",
    "        tries = 0\n",
    "        while not clicked and tries < MAX_RETRY:\n",
    "            try:\n",
    "                menu_bt = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@data-value=\\'Sort\\']')))\n",
    "                menu_bt.click()\n",
    "\n",
    "                clicked = True\n",
    "                time.sleep(3)\n",
    "            except Exception as e:\n",
    "                tries += 1\n",
    "                self.logger.warning('Failed to click sorting button')\n",
    "\n",
    "            # failed to open the dropdown\n",
    "            if tries == MAX_RETRY:\n",
    "                return -1\n",
    "\n",
    "        #  element of the list specified according to ind\n",
    "        recent_rating_bt = self.driver.find_elements_by_xpath('//div[@role=\\'menuitemradio\\']')[ind]\n",
    "        recent_rating_bt.click()\n",
    "\n",
    "        # wait to load review (ajax call)\n",
    "        time.sleep(5)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def getPlaces(self, method='urls', keyword_list=None):\n",
    "\n",
    "        df_places = pd.DataFrame()\n",
    "\n",
    "        if method == 'urls':\n",
    "            # search_point_url = row['url']  # TODO:\n",
    "            pass\n",
    "        if method == 'squares':\n",
    "            search_point_url_list = self._genSearchPointsFromSquare(keyword_list=keyword_list)\n",
    "        else:\n",
    "            # search_point_url = f\"https://www.google.com/maps/search/{row['keyword']}/@{str(row['longitude'])},{str(row['latitude'])},{str(row['zoom'])}z\"\n",
    "            # TODO:\n",
    "            pass\n",
    "\n",
    "        for i, search_point_url in enumerate(search_point_url_list):\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"{i}/{len(search_point_url_list)}\")\n",
    "                df_places = df_places[['search_point_url', 'href', 'name', 'rating', 'num_reviews', 'close_time', 'other']]\n",
    "                df_places.to_csv('output/places_wax.csv', index=False)\n",
    "\n",
    "\n",
    "            try:\n",
    "                self.driver.get(search_point_url)\n",
    "            except NoSuchElementException:\n",
    "                self.driver.quit()\n",
    "                self.driver = self.__getDriver()\n",
    "                self.driver.get(search_point_url)\n",
    "\n",
    "            # Gambiarra to load all places into the page\n",
    "            scrollable_div = self.driver.find_element_by_css_selector(\n",
    "                \"div.siAUzd-neVct.section-scrollbox.cYB2Ge-oHo7ed.cYB2Ge-ti6hGc > div[aria-label*='Results for']\")\n",
    "            for i in range(10):\n",
    "                self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "\n",
    "            # Get places names and href\n",
    "            # time.sleep(2)\n",
    "            response = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            div_places = response.select('div[jsaction] > a[href]')\n",
    "            for div_place in div_places:\n",
    "                place_info = {\n",
    "                    'search_point_url': search_point_url.replace('https://www.google.com/maps/search/', ''),\n",
    "                    'href': div_place['href'],\n",
    "                    'name': div_place['aria-label'],\n",
    "                    'rating': None,\n",
    "                    'num_reviews': None,\n",
    "                    'close_time': None,\n",
    "                    'other': None\n",
    "                }\n",
    "\n",
    "                df_places = df_places.append(place_info, ignore_index=True)\n",
    "        df_places = df_places[['search_point_url', 'href', 'name', 'rating', 'num_reviews', 'close_time', 'other']]\n",
    "        df_places.to_csv('output/places_wax.csv', index=False)\n",
    "        self.driver.quit()\n",
    "\n",
    "    def _genSearchPointsFromSquare(self, keyword_list=None):\n",
    "        keyword_list = [] if keyword_list is None else keyword_list\n",
    "\n",
    "        square_points = pd.read_csv('input/square_points.csv')\n",
    "\n",
    "        cities = square_points['city'].unique()\n",
    "\n",
    "        search_urls = []\n",
    "\n",
    "        for city in cities:\n",
    "            df_aux = square_points[square_points['city'] == city]\n",
    "            latitudes = np.linspace(df_aux['latitude'].min(), df_aux['latitude'].max(), num=20)\n",
    "            longitudes = np.linspace(df_aux['longitude'].min(), df_aux['longitude'].max(), num=20)\n",
    "            coordinates_list = list(itertools.product(latitudes, longitudes, keyword_list))\n",
    "\n",
    "            search_urls += [f\"https://www.google.com/maps/search/{coordinates[2]}/@{str(coordinates[1])},{str(coordinates[0])},{str(15)}z\"\n",
    "             for coordinates in coordinates_list]\n",
    "\n",
    "        return search_urls\n",
    "\n",
    "\n",
    "\n",
    "    # Triggers scroll which then triggers loading of next patch of reviews\n",
    "    # It then expands reviews, query the DOM and iterates through each review to parse it\n",
    "    # Returns list of parsed reviews\n",
    "    def getReviews(self, offset):\n",
    "        # wait for other reviews to load (ajax)\n",
    "        time.sleep(4)\n",
    "\n",
    "        self.__scroll()\n",
    "\n",
    "        # expand review text\n",
    "        self.__expandReviews()\n",
    "\n",
    "        # parse reviews\n",
    "        response = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        \n",
    "        # TODO: Subject to changes\n",
    "        rblock = response.find_all('div', class_='jftiEf fontBodyMedium')\n",
    "        \n",
    "        parsed_reviews = []\n",
    "        for index, review in enumerate(rblock):\n",
    "            if index >= offset:\n",
    "                parsed_reviews.append(self.__parse(review))\n",
    "        return parsed_reviews\n",
    "\n",
    "\n",
    "    def __parse(self, review):\n",
    "        item = {}\n",
    "\n",
    "\n",
    "        try:\n",
    "            # TODO: Subject to changes\n",
    "            id_review = review['data-review-id']\n",
    "        except Exception as e:\n",
    "            id_review = None\n",
    "\n",
    "        try:\n",
    "            # TODO: Subject to changes\n",
    "            review_text = self.__filterString(review.find('span', class_='wiI7pd').text)\n",
    "        except Exception as e:\n",
    "            review_text = None\n",
    "\n",
    "        try:\n",
    "            # TODO: Subject to changes\n",
    "            rating = float(review.find('span', class_='kvMYJc')['aria-label'].split(' ')[1])\n",
    "        except Exception as e:\n",
    "            rating = None\n",
    "\n",
    "        try:\n",
    "            # TODO: Subject to changes\n",
    "            relative_date = review.find('span', class_='rsqaWe').text\n",
    "        except Exception as e:\n",
    "            relative_date = None\n",
    "\n",
    "        item['id_review'] = id_review\n",
    "        item['caption'] = review_text\n",
    "        item['relative_date'] = relative_date\n",
    "        item['rating'] = rating\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __parsePlace(self, response):\n",
    "        place = {}\n",
    "        try:\n",
    "            place['overall_rating'] = float(response.find('div', class_='gm2-display-2').text.replace(',', '.'))\n",
    "        except:\n",
    "            place['overall_rating'] = 'NOT FOUND'\n",
    "\n",
    "        try:\n",
    "            place['n_reviews'] = int(response.find('div', class_='gm2-caption').text.replace('.', '').replace(',','').split(' ')[0])\n",
    "        except:\n",
    "            place['n_reviews'] = 0\n",
    "        \n",
    "        return place\n",
    "\n",
    "    # expand review content - click on each expand button which then replaces the ellipsized text\n",
    "    # use XPath to load complete reviews\n",
    "    def __expandReviews(self):\n",
    "        # TODO: Subject to changes\n",
    "        links = self.driver.find_elements_by_xpath('//button[@jsaction=\"pane.review.expandReview\"]')\n",
    "        for l in links:\n",
    "            l.click()\n",
    "        wait = WebDriverWait(self.driver, 1) # 2\n",
    "            \n",
    "    # scroll the review container element to show the next patch of reviews\n",
    "    def __scroll(self):\n",
    "        scrollable_div = self.driver.find_element_by_css_selector('div.m6QErb.DxyBCb.kA9KIf.dS8AEf')\n",
    "        self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "\n",
    "\n",
    "    def __getLogger(self):\n",
    "        # create logger\n",
    "        logger = logging.getLogger('googlemaps-scraper')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # create console handler and set level to debug\n",
    "        fh = logging.FileHandler('gm-scraper.log')\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "\n",
    "        # create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "        # add formatter to ch\n",
    "        fh.setFormatter(formatter)\n",
    "\n",
    "        # add ch to logger\n",
    "        logger.addHandler(fh)\n",
    "        return logger\n",
    "\n",
    "\n",
    "    def __getDriver(self, debug=False):\n",
    "        options = Options()\n",
    "\n",
    "        if not self.debug:\n",
    "            options.add_argument(\"--headless\")\n",
    "        else:\n",
    "            options.add_argument(\"--window-size=1366,768\")\n",
    "\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en-GB\")\n",
    "        input_driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=options)\n",
    "\n",
    "         # click on google agree button so we can continue (not needed anymore)\n",
    "         # EC.element_to_be_clickable((By.XPATH, '//span[contains(text(), \"I agree\")]')))\n",
    "        input_driver.get(GM_WEBPAGE)\n",
    "        return input_driver\n",
    "\n",
    "    # cookies agreement click\n",
    "    def __clickOnCookieAgreement(self):\n",
    "        try:\n",
    "            agree = WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//span[contains(text(), \"Reject all\")]')))\n",
    "            agree.click()\n",
    "\n",
    "            # back to the main page\n",
    "            # self.driver.switch_to_default_content()\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    # util function to clean special characters\n",
    "    def __filterString(self, str):\n",
    "        strOut = str.replace('\\r', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "        return strOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "69023a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "collection = [];\n",
    "class ReviewGatherer:\n",
    "    def __init__(self, url_file, from_date):\n",
    "\n",
    "        # load urls file\n",
    "        with open(url_file, 'r') as furl:\n",
    "            self.urls = [u[:-1] for u in furl]\n",
    "\n",
    "        # min date review to scrape\n",
    "        self.min_date_review = datetime.strptime(from_date, '%Y-%m-%d')\n",
    "\n",
    "        # logging\n",
    "        self.logger = self.__getLogger()\n",
    "\n",
    "    def scrapeGMReviews(self):\n",
    "        # init scraper and incremental add reviews\n",
    "        # TO DO: pass logger as parameter to log into one single file?\n",
    "        with GoogleMapsScraper(debug=True) as scraper:\n",
    "            for url in self.urls:\n",
    "                try:\n",
    "                    #ind = {'most_relevant' : 0 , 'newest' : 1, 'highest_rating' : 2, 'lowest_rating' : 3 }\n",
    "                    error = scraper.sortBy(url, 1)\n",
    "                    \n",
    "                    if error == 0:\n",
    "                        stop = False\n",
    "                        offset = 0\n",
    "                        n_new_reviews = 0\n",
    "                        while not stop:\n",
    "                            rlist = scraper.getReviews(offset)\n",
    "                            for r in rlist:\n",
    "                                # calculate review date and compare to input min_date_review\n",
    "                                r['timestamp'] = self.__parseRelativeDate(r['relative_date'])\n",
    "                                stop = self.__stop(r)\n",
    "                                if not stop:\n",
    "                                    collection.append(r)\n",
    "                                    n_new_reviews += 1\n",
    "                                else:\n",
    "                                    break\n",
    "                            offset += len(rlist)\n",
    "\n",
    "                        # log total number\n",
    "                        self.logger.info('{} : {} new reviews'.format(url, n_new_reviews))\n",
    "                    else:\n",
    "                        self.logger.warning('Sorting reviews failed for {}'.format(url))\n",
    "                except Exception as e:\n",
    "                    self.logger.error('Exception: {}'.format(e))\n",
    "                    \n",
    "        return(collection)\n",
    "\n",
    "\n",
    "    def __parseRelativeDate(self, string_date):\n",
    "        curr_date = datetime.now()\n",
    "        split_date = string_date.split(' ')\n",
    "\n",
    "        n = split_date[0]\n",
    "        delta = split_date[1]\n",
    "\n",
    "        if delta == 'year':\n",
    "            return curr_date - timedelta(days=365)\n",
    "        elif delta == 'years':\n",
    "            return curr_date - timedelta(days=365 * int(n))\n",
    "        elif delta == 'month':\n",
    "            return curr_date - timedelta(days=30)\n",
    "        elif delta == 'months':\n",
    "            return curr_date - timedelta(days=30 * int(n))\n",
    "        elif delta == 'week':\n",
    "            return curr_date - timedelta(weeks=1)\n",
    "        elif delta == 'weeks':\n",
    "            return curr_date - timedelta(weeks=int(n))\n",
    "        elif delta == 'day':\n",
    "            return curr_date - timedelta(days=1)\n",
    "        elif delta == 'days':\n",
    "            return curr_date - timedelta(days=int(n))\n",
    "        elif delta == 'hour':\n",
    "            return curr_date - timedelta(hours=1)\n",
    "        elif delta == 'hours':\n",
    "            return curr_date - timedelta(hours=int(n))\n",
    "        elif delta == 'minute':\n",
    "            return curr_date - timedelta(minutes=1)\n",
    "        elif delta == 'minutes':\n",
    "            return curr_date - timedelta(minutes=int(n))\n",
    "        elif delta == 'moments':\n",
    "            return curr_date - timedelta(seconds=1)\n",
    "\n",
    "\n",
    "    def __stop(self, r):\n",
    "        review_list = [x for x in collection if x['id_review'] == r['id_review']];\n",
    "        is_old_review = review_list[0] if len(review_list) != 0 else None\n",
    "        \n",
    "        if is_old_review is None and r['timestamp'] >= self.min_date_review:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def __getLogger(self):\n",
    "        # create logger\n",
    "        logger = logging.getLogger('monitor')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        # create console handler and set level to debug\n",
    "        fh = logging.FileHandler('monitor.log')\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "        # create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        # add formatter to ch\n",
    "        fh.setFormatter(formatter)\n",
    "        # add ch to logger\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "        return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "65ffbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatherer = ReviewGatherer(\"urls.text\", '2023-01-15')\n",
    "\n",
    "try:\n",
    "    gatherer.scrapeGMReviews()\n",
    "except Exception as e:\n",
    "    gatherer.logger.error('Not handled error: {}'.format(e))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "03c15b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.DataFrame.from_records(collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "28003e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews[['caption', 'rating', 'timestamp']].to_csv('reviews.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b6dde0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>caption</th>\n",
       "      <th>relative_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSURCN2Q2WUpnEAE</td>\n",
       "      <td>Absolutely fantastic pizza. This is definitely one of the best if not the best pizza places in Frankfurt. They were fully packed on a weeknight so reservations are highly recommended.</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-01-26 09:45:52.538831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSURCcmRUMkxREAE</td>\n",
       "      <td>Sehr chillige Pizzeria! Immer gute Laune der Angestellten ,fast schon partymäßig! Pizza,Mega ! Extrem hochwertiger Belag, auch obwohl ich normalerweise die  krossen Pizzen mehr schätze, gehe ich dort immer wieder hin, weil wie gesagt, der leckere Belag alles ausgleicht… Sie werden ja nun mal nur 90 Sekunden in den Ofen bei hoher Temperatur  zubereitet und da wird die Pizza nicht richtig kross im Teig ,aber dafür sehr lecker und vom Steinofen her optimal. Der Teig schmeckt auch sehr gut an sich . Was auch sehr löblich ist, man kann die Pizza, mit in die Brauerei nehmen ,neben an. Drinnen wie draußen ,im Freien konsumieren,ein Bierchen dort trinken und die Pizza von nebenan essen ! Auch umgekehrt … kann man sich ein leckeres frisch gezapftes Bier mit in die Pizzeria rein nehmen! Wo hat man so eine tolle Kooperation ? fantastisch ! Es läuft immer eine sehr angenehme Musik partymäßig angenehm. Die Leute sind freundlich 😉,es herrscht eine sehr schöne Atmosphäre und es ist immer rappelvoll! Man sollte eigentlich seine Pizza nicht später als sechs konsumieren ,danach wird es brechend voll! Oder wann kommt spät, Bitte die last Order beachten ,unterschiedliche Öffnungszeiten… Gehört zu den besten Pizzerien in Frankfurt!  (Translated by Google) Very chilled pizzeria! The employees are always in a good mood, almost like a party! Pizza, mega! Extremely high-quality toppings, even though I usually appreciate the crispy pizzas more, I keep going there because, as I said, the delicious toppings balance everything out... They are only prepared for 90 seconds in the oven at a high temperature and the pizza is not really crispy in the dough, but it is very tasty and the stone oven is ideal. The dough itself tastes really good too. Which is also very praiseworthy, you can take the pizza to the brewery next door. Inside and outside, consume outdoors, have a beer there and eat the pizza next door! Also vice versa... you can take a delicious freshly tapped beer to the pizzeria! Where do you have such a great cooperation? fantastic ! There is always a very pleasant music playing in a party-like way. The people are friendly 😉, there is a very nice atmosphere and it is always packed! You should actually eat your pizza no later than six, after that it gets packed! Or when is it late, please note the last order, different opening times... One of the best pizzerias in Frankfurt!</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-01-26 01:45:52.538840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSURCamJhcFNnEAE</td>\n",
       "      <td>Hands down, best pizza in town.</td>\n",
       "      <td>a day ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-01-25 22:45:52.538843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSURCNFlmM1ZBEAE</td>\n",
       "      <td>Sehr geil  (Translated by Google) very cool</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-01-21 22:45:52.538854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURCX1AteW1BRRAB</td>\n",
       "      <td>Super leckere, gute belegte Pizza. Extrem dünn in der Mitte, dafür dicker fluffiger Rand. \"Normale\" deutsche Sorten (z.B. Hawaii) sucht man hier vergeblich, aber das ist auch gut so! Das hier ist deutlich italienischer. …</td>\n",
       "      <td>a week ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-01-19 22:45:52.538856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id_review  \\\n",
       "1   ChZDSUhNMG9nS0VJQ0FnSURCN2Q2WUpnEAE   \n",
       "2   ChZDSUhNMG9nS0VJQ0FnSURCcmRUMkxREAE   \n",
       "3   ChZDSUhNMG9nS0VJQ0FnSURCamJhcFNnEAE   \n",
       "7   ChZDSUhNMG9nS0VJQ0FnSURCNFlmM1ZBEAE   \n",
       "8  ChdDSUhNMG9nS0VJQ0FnSURCX1AteW1BRRAB   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     caption  \\\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Absolutely fantastic pizza. This is definitely one of the best if not the best pizza places in Frankfurt. They were fully packed on a weeknight so reservations are highly recommended.   \n",
       "2  Sehr chillige Pizzeria! Immer gute Laune der Angestellten ,fast schon partymäßig! Pizza,Mega ! Extrem hochwertiger Belag, auch obwohl ich normalerweise die  krossen Pizzen mehr schätze, gehe ich dort immer wieder hin, weil wie gesagt, der leckere Belag alles ausgleicht… Sie werden ja nun mal nur 90 Sekunden in den Ofen bei hoher Temperatur  zubereitet und da wird die Pizza nicht richtig kross im Teig ,aber dafür sehr lecker und vom Steinofen her optimal. Der Teig schmeckt auch sehr gut an sich . Was auch sehr löblich ist, man kann die Pizza, mit in die Brauerei nehmen ,neben an. Drinnen wie draußen ,im Freien konsumieren,ein Bierchen dort trinken und die Pizza von nebenan essen ! Auch umgekehrt … kann man sich ein leckeres frisch gezapftes Bier mit in die Pizzeria rein nehmen! Wo hat man so eine tolle Kooperation ? fantastisch ! Es läuft immer eine sehr angenehme Musik partymäßig angenehm. Die Leute sind freundlich 😉,es herrscht eine sehr schöne Atmosphäre und es ist immer rappelvoll! Man sollte eigentlich seine Pizza nicht später als sechs konsumieren ,danach wird es brechend voll! Oder wann kommt spät, Bitte die last Order beachten ,unterschiedliche Öffnungszeiten… Gehört zu den besten Pizzerien in Frankfurt!  (Translated by Google) Very chilled pizzeria! The employees are always in a good mood, almost like a party! Pizza, mega! Extremely high-quality toppings, even though I usually appreciate the crispy pizzas more, I keep going there because, as I said, the delicious toppings balance everything out... They are only prepared for 90 seconds in the oven at a high temperature and the pizza is not really crispy in the dough, but it is very tasty and the stone oven is ideal. The dough itself tastes really good too. Which is also very praiseworthy, you can take the pizza to the brewery next door. Inside and outside, consume outdoors, have a beer there and eat the pizza next door! Also vice versa... you can take a delicious freshly tapped beer to the pizzeria! Where do you have such a great cooperation? fantastic ! There is always a very pleasant music playing in a party-like way. The people are friendly 😉, there is a very nice atmosphere and it is always packed! You should actually eat your pizza no later than six, after that it gets packed! Or when is it late, please note the last order, different opening times... One of the best pizzerias in Frankfurt!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Hands down, best pizza in town.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Sehr geil  (Translated by Google) very cool   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Super leckere, gute belegte Pizza. Extrem dünn in der Mitte, dafür dicker fluffiger Rand. \"Normale\" deutsche Sorten (z.B. Hawaii) sucht man hier vergeblich, aber das ist auch gut so! Das hier ist deutlich italienischer. …   \n",
       "\n",
       "  relative_date  rating                  timestamp  \n",
       "1  13 hours ago     5.0 2023-01-26 09:45:52.538831  \n",
       "2  21 hours ago     5.0 2023-01-26 01:45:52.538840  \n",
       "3     a day ago     5.0 2023-01-25 22:45:52.538843  \n",
       "7    5 days ago     5.0 2023-01-21 22:45:52.538854  \n",
       "8    a week ago     5.0 2023-01-19 22:45:52.538856  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.loc[df_reviews['caption'] != ''].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2359f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
