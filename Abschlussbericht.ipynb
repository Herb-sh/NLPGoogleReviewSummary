{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6c2be",
   "metadata": {},
   "source": [
    "<img src=\"images/hs-aalen-logo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083311cf",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30228542",
   "metadata": {},
   "source": [
    "\n",
    "# Abschlussbericht Analyseprojekt \"Google Reviews Mining\"\n",
    "\n",
    "    Text Mining und Web Analytics \n",
    "    Sommersemester 2023\n",
    "    Christian Wilhelm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83464c",
   "metadata": {},
   "source": [
    "Laura Tatlik // Data Science und Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5132677",
   "metadata": {},
   "source": [
    "<img src=\"images/Laura.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8c1e3",
   "metadata": {},
   "source": [
    "Bastian Rütters // Data Science und Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f51d1c",
   "metadata": {},
   "source": [
    "<img src=\"images/Bastian.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596561f",
   "metadata": {},
   "source": [
    "Herbi Shtini // Data Science und Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40e231",
   "metadata": {},
   "source": [
    "<img src=\"images/Herbi.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28414371",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "67a643ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NLP-Module\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import minibatch\n",
    "from spacy.training import Example\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n",
    "from wordcloud import WordCloud\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "\n",
    "# Module zur Datenbearbeitung und Visualisierung\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Module zur Vorhersagung der neuen Bewertung\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sontige Module\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "37d0d8d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a344f40",
   "metadata": {},
   "source": [
    "## Inhaltsverzeichnis\n",
    "\n",
    "1 Einleitung<br>\n",
    "2 CRISP-DM<br>\n",
    "&nbsp;&nbsp;&nbsp;2.1 Business Understanding<br>\n",
    "&nbsp;&nbsp;&nbsp;2.2 Data Preparation<br>\n",
    "&nbsp;&nbsp;&nbsp;2.3 Data Understanding<br>\n",
    "&nbsp;&nbsp;&nbsp;2.4 Modeling<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.4.1 Erster Ansatz mit NLP-TfidfVectorizer<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.4.2 Vorhersage der Bewertung<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.4.3 Bewertung des Ergebnis<br>\n",
    "&nbsp;&nbsp;&nbsp;2.5 Evaluation<br>\n",
    "&nbsp;&nbsp;&nbsp;2.6 Deployment<br>\n",
    "3 Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f77d28",
   "metadata": {},
   "source": [
    "## 1 Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd2edd",
   "metadata": {},
   "source": [
    "Dieser Bericht dient als Ergänzung zu der schriftlichen Ausarbeitung um vor allem den geschriebenen Code in diesem Projekt gut veranschaulichen zu können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656313dd",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5211f1",
   "metadata": {},
   "source": [
    "## 2 CRISP-DM\n",
    "<img src=\"images/CRISP-DM_klein.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa20aac",
   "metadata": {},
   "source": [
    "### 2.1 Business Understanding\n",
    "Nahezu jeder hat sich in Zeiten der Digitalisierung bei der Suche nach einem geeigneten Restaurant oder Lieferdienst, bereits an den Bewertungen im Internet anderer Kunden bedient und anschließend darauf eine Entscheidung für oder gegen eine mögliche Location entschieden. Ob nach der Entscheidung aber genau die eigenen Bedürfnisse entsprechend befriedigt werden, bleibt offen bis zur eigenen Erfahrung. Im folgenden Jupyter Notebook wird die Herangehensweise und Methodik anhand von Code, Codekommentaren und Markdown-Felder erkläutert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809b2aa",
   "metadata": {},
   "source": [
    "<img src=\"images/Project_Canvas.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbd086",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be9ad45",
   "metadata": {},
   "source": [
    "### 2.2 Data Preparation\n",
    "Die Phase der Datenvorbereitung umfasst alle Aktivitäten zur Erstellung des endgültigen Datensatzes oder der Daten, die aus den anfänglichen Rohdaten in das Modell eingespeist werden. Zu den Aufgaben gehören die Auswahl von Tabellen, Datensätzen und Attributen sowie die Umwandlung und Bereinigung von Daten für das Modell [1].\n",
    "\n",
    "Die Rohdaten für dieses Projekt werden durch den Scraper (../scrapper/GoogleReviewScrapper.ipynb) von Google Maps extrahiert und als csv-Datei in ../data/reviews.csv gespeichert.\n",
    "\n",
    "Gescrapt wurden die Bewertungen von 3 Restauraunts/Imbissbuden:\n",
    "\n",
    "- Super Bros: Pizzaria in Frankfurt am Main\n",
    "- Dene Gör: Dönerladen in Düsseldorf\n",
    "- Space Burger: Burgerladen in Düsseldorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4b8067b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der gescrapten Daten\n",
    "REVIEWS_FILE_PATH = 'data/reviews_merged.csv'\n",
    "REVIEWS_CLEANED_FILE_PATH = 'data/reviews_merged_cleaned.csv'\n",
    "REVIEWS_CLEANED_UNLABELED_FILE_PATH = 'data/reviews_merged_unlabeled_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(REVIEWS_FILE_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a7d11b59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['caption',\n",
    "              'food_positive', 'food_negative',\n",
    "              'service_positive', 'service_negative',\n",
    "              'ambient_positive', 'ambient_negative',\n",
    "              'price_positive', 'price_negative',\n",
    "              'waiting_positive', 'waiting_negative',\n",
    "              'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc5b97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen aller Datenpunkte mit NaN\n",
    "USEFUL_COLUMNS = ['caption',\n",
    "                  'food_positive', 'service_positive', 'ambient_positive', 'price_positive', 'waiting_positive', 'rating']\n",
    "df = df.loc[~df['caption'].isnull(), USEFUL_COLUMNS]\n",
    "\n",
    "# Indexspalte entfernen\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "# Übersicht über bearbeiteten Dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translated by Google aus den Bewertungen entfernen\n",
    "df['caption'] = df['caption'].str.split('(Translated by Google)').str[0]\n",
    "\n",
    "# Übersicht über bearbeiteten Dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über Stop-Words in der deutschen Sprache\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGX_USERNAME = r\"@[A-Za-z0-9$-_@.&+]+\"\n",
    "REGX_URL = r\"https?://[A-Za-z0-9./]+\"\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Benutzernamen und URLs aus dem Text entfernen\n",
    "    text = re.sub(REGX_USERNAME, ' ', text)\n",
    "    text = re.sub(REGX_URL, ' ', text)\n",
    "\n",
    "    # Emojis durch Text ersetzen\n",
    "    emojis = {\n",
    "        ':)': 'positive emotionen',\n",
    "        ':(': 'negative emotionen'\n",
    "    }\n",
    "\n",
    "    for e in emojis:\n",
    "        text = text.replace(e, emojis[e])\n",
    "        \n",
    "    # Tokenisiere den Text mit dem SpaCy-Modell\n",
    "    tokens = [token.text for token in nlp(text)]\n",
    "\n",
    "    # Entferne Stoppwörter, Interpunktion und Wörter mit weniger als 3 Zeichen.\n",
    "    tokens = [t for t in tokens if\n",
    "              t not in STOP_WORDS and\n",
    "              t not in string.punctuation and\n",
    "              len(t) > 3]\n",
    "    \n",
    "    # Zahlen aus dem Text entfernen\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "    \n",
    "    text = \" \".join(tokens);\n",
    "\n",
    "    # Lemmatisierung\n",
    "    '''\n",
    "    allowed_postags = [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    "    doc = nlp(text)\n",
    "    new_text = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in allowed_postags:\n",
    "            new_text.append(token.lemma_)\n",
    "    lemmatized = \" \".join(new_text).lower()\n",
    "    '''\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fbfad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion \"preprocessing\" auf die Spalte \"caption\" anwenden und in die neue Spalte \"caption_clean\" hinzufügen\n",
    "df[\"caption_clean\"] = df[\"caption\"].apply(preprocessing)\n",
    "\n",
    "# df Dataframe\n",
    "USEFUL_COLUMNS_AND_CLEAN = USEFUL_COLUMNS[:]\n",
    "# Die Spalte 'caption' wird zu diesem Zeitpunkt nicht ausgewählt,\n",
    "# stattdessen wird 'caption_clean' genommen.\n",
    "USEFUL_COLUMNS_AND_CLEAN.remove('caption')\n",
    "USEFUL_COLUMNS_AND_CLEAN.append('caption_clean') # Select caption_clean\n",
    "\n",
    "\n",
    "df = df[USEFUL_COLUMNS_AND_CLEAN]\n",
    "\n",
    "# Die Spalte 'caption_clean' jetzt mit 'caption' ersetzen\n",
    "df = df.rename(columns={\"caption_clean\": \"caption\"}) #\n",
    "USEFUL_COLUMNS_AND_CLEAN.append('caption') # add caption\n",
    "USEFUL_COLUMNS_AND_CLEAN.remove('caption_clean') # Remove caption_clean\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f26252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Übersicht über bearbeitete Daten\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8058f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erneutes löschen der NaN Werte in bearbeiteten Spalten\n",
    "df = df.loc[~df['caption'].isnull(), USEFUL_COLUMNS_AND_CLEAN]\n",
    "df = df[df['caption'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über die Spalte mit dem Text\n",
    "df['caption'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c57264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe als csv-Datei abspeichern\n",
    "df[['caption', 'rating']].to_csv(REVIEWS_CLEANED_UNLABELED_FILE_PATH, sep=';')\n",
    "df.to_csv(REVIEWS_CLEANED_FILE_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c54d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20bb57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(REVIEWS_CLEANED_UNLABELED_FILE_PATH, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af4451",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['essen', 'service', 'atmosphäre', 'preis', 'warten']\n",
    "categories_columns = ['food_positive', 'food_negative',\n",
    "                      'service_positive', 'service_negative',\n",
    "                      'ambient_positive', 'ambient_negative',\n",
    "                      'price_positive', 'price_negative',\n",
    "                      'waiting_positive', 'waiting_negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f3246",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def spacy_most_similar(word, topn=10):\n",
    "    \"\"\"\n",
    "    Diese Funktion gibt eine Liste von Wörtern zurück, die den Eingabewortvektor von spaCy am ähnlichsten sind. \n",
    "\n",
    "    Argumente:\n",
    "        - word (str): Das Wort, für das die ähnlichsten Wörter gefunden werden sollen\n",
    "        - topn (int): Die Anzahl der ähnlichsten Wörter, die zurückgegeben werden sollen (Standardwert: 10)\n",
    "\n",
    "    Rückgabewert:\n",
    "        - words (list): Eine Liste von Wörtern, die den Eingabewortvektor von spaCy am ähnlichsten sind\n",
    "        - distances (list): Eine Liste von Distanzen zwischen den ähnlichsten Wörtern und dem Eingabewortvektor    \n",
    "    \"\"\"\n",
    "\n",
    "    ms = nlp.vocab.vectors.most_similar(\n",
    "        nlp(word).vector.reshape(1,nlp(word).vector.shape[0]), n=topn)\n",
    "    words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    distances = ms[2]\n",
    "    return words, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67accc3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spacy_most_similar(categories[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6d9e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Aspektbasierte Stimmungsanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77352a",
   "metadata": {},
   "source": [
    "Folgender Code sucht in den Texten des \"caption\"-Felds eines Dataframes nach bestimmten Mustern (patterns), verwendet dabei den Matcher von spaCy und bestimmt für jede Übereinstimmung eine passende Kategorie basierend auf der Ähnlichkeit des gefundenen Textes mit vordefinierten Kategorien. Gefundene Übereinstimmungen werden mit ihrer Kategorie und ihrem Index im ursprünglichen Dataframe in einem neuen Dataframe namens \"df_matches\" gespeichert und ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ea478",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "patterns = [\n",
    "    [{'POS':'ADJ', 'OP': '+'}, {'POS':'NOUN'}],\n",
    "    [{'POS':'NOUN'}, {'POS':'VERB'}, {'POS':'ADJ'}]\n",
    "]\n",
    "matcher.add(\"category\", patterns)\n",
    "\n",
    "df_matches = pd.DataFrame([], columns=['index', 'aspect', 'entity_group'])\n",
    "\n",
    "similarity_min = 0.4\n",
    "\n",
    "for rowIndex, wordText in enumerate(df['caption']):\n",
    "    doc = nlp(wordText)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]\n",
    "        span = doc[start:end]\n",
    "\n",
    "        for i, s in enumerate(span):\n",
    "            if s.pos_ in ['NOUN']:\n",
    "                category = ''\n",
    "                similarity = 0\n",
    "\n",
    "                similarity_cat0 = nlp(categories[0]).similarity(span)\n",
    "                if similarity_cat0 > similarity_min: # fits into\n",
    "                    category = categories[0]\n",
    "                    similarity = similarity_cat0\n",
    "\n",
    "                print(span)\n",
    "                similarity_cat1 = nlp(categories[1]).similarity(span)\n",
    "                if similarity_cat1 > similarity_min: # fits into\n",
    "                    category = categories[1]\n",
    "                    similarity = similarity_cat1\n",
    "\n",
    "                similarity_cat2 = nlp(categories[2]).similarity(span)\n",
    "                if similarity_cat2 > similarity_min: # fits into\n",
    "                    category = categories[2]\n",
    "                    similarity = similarity_cat2\n",
    "\n",
    "                similarity_cat3 = nlp(categories[3]).similarity(span)\n",
    "                if similarity_cat3 > similarity_min: # fits into\n",
    "                    category = categories[3]\n",
    "                    similarity = similarity_cat3\n",
    "\n",
    "                similarity_cat4 = nlp(categories[4]).similarity(span)\n",
    "                if similarity_cat4 > similarity_min: # fits into\n",
    "                    category = categories[4]\n",
    "                    similarity = similarity_cat4\n",
    "\n",
    "                df_matches = pd.concat([pd.DataFrame({'index': rowIndex,\n",
    "                                                      'aspect': category,\n",
    "                                                      'entity_group': span.text,\n",
    "                                                      }, columns=df_matches.columns, index=[0]),\n",
    "                                        df_matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48d3c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628219e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####  TextBlob Stimmungsanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e027ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung von zwei leeren Listen\n",
    "sentiment_polarities = []\n",
    "sentiment_subjectivities = []\n",
    "\n",
    "# Iteration durch jede Zeile des Dataframes \"df_matches\"\n",
    "for i, row in df_matches.iterrows():\n",
    "    # Berechnung des Sentiments (Polarität und Subjektivität) des entity_groups-Texts mit TextBlob\n",
    "    sentiment = TextBlob(row['entity_group']).sentiment\n",
    "    # Hinzufügen der Polarität des Sentiments zur sentiment_polarities-Liste\n",
    "    sentiment_polarities.append(sentiment.polarity)\n",
    "    # Hinzufügen der Subjektivität des Sentiments zur sentiment_subjectivities-Liste\n",
    "    sentiment_subjectivities.append(sentiment.subjectivity)\n",
    "\n",
    "# Hinzufügen der Spalten \"sentiment_polarity\" und \"sentiment_subjectivity\" zum df_matches-Dataframe \n",
    "df_matches['sentiment_polarity'] = sentiment_polarities\n",
    "df_matches['sentiment_subjectivity'] = sentiment_subjectivities\n",
    "\n",
    "# Sortierung des df_matches-Dataframes nach dem Index der ursprünglichen Zeilen\n",
    "df_matches_sorted = df_matches.sort_values(by='index')\n",
    "# Ausgabe des df_matches_sorted-Dataframes\n",
    "print(df_matches_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7571b92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166fa8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Durch alle df_matches laufen\n",
    "# Prüft für jeden Index den Aspekt, ob er einer Kategorie entspricht\n",
    "# Aktualisiert die richtige Kategorie von df mit der jeweiligen Stimmung\n",
    "for column in categories_columns:\n",
    "    df[column] = 0\n",
    "\n",
    "for rowIndex, row in df.iterrows():\n",
    "    entities_by_index = df_matches_sorted.loc[df_matches_sorted['index'] == rowIndex]\n",
    "    # reset\n",
    "    for j, item in entities_by_index.iterrows():\n",
    "        if item['aspect'] != '':\n",
    "            category_i = categories.index(item['aspect'])\n",
    "            polarity = item['sentiment_polarity']\n",
    "            if polarity != 0:\n",
    "                column_index = (category_i * 2) if polarity > 0 else (category_i * 2) + 1\n",
    "                df.at[rowIndex, categories_columns[column_index]] = 1\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ceb3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(REVIEWS_CLEANED_FILE_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ca050",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1c9fb",
   "metadata": {},
   "source": [
    "### 2.3 Data Understanding\n",
    "Die zweite Phase im CIRSP-DM Model, das Data Understanding, ist der Schritt, in dem man Daten aus verschiedenen Quellen sammelt, aufbereitet, untersucht, relevante Daten für die Analyse auswählt, Datenziele anpasst, mögliche Datenprobleme identifiziert und ein besseres Verständnis der Daten erhält, um fundierte Entscheidungen für die weitere Analyse treffen zu können [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec08e99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Relativen Pfad definieren\n",
    "REVIEWS_CLEANED_FILE_PATH = 'data/reviews_merged_cleaned.csv'\n",
    "\n",
    "# Einlesen der bearbeiteten Daten\n",
    "df = pd.read_csv(REVIEWS_CLEANED_FILE_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6f927",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Alle Bewertungen in einen langen String joinen\n",
    "full_caption_text = '. '.join(df['caption'])\n",
    "len(full_caption_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0645161",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion um die meist genutzten Wörter zu ermitteln\n",
    "def getWordFrequency(text, pos=\"NOUN\", top_items=0):\n",
    "    doc = nlp(text)\n",
    "    words = [token.lemma_\n",
    "             for token in doc\n",
    "             if (not token.is_stop and not token.is_punct and (pos == \"\" or token.pos_ == pos))]\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    return(dict(word_freq.most_common(top_items) if top_items else word_freq.most_common()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07870d2c",
   "metadata": {},
   "source": [
    "#### Anzahl der Google-Bewertungen pro Bewertungsgruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab3081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Axen initialisieren\n",
    "f, ax = plt.subplots(1,1)\n",
    "# Ermitteln der Anzahl der Sterne-Bewertungen\n",
    "ratings = df['rating'].value_counts().reset_index()\n",
    "# Spalten definieren\n",
    "ratings.columns = ['rating', 'count']\n",
    "# Abstiegend sortieren\n",
    "ratings = ratings.sort_values(by=['rating'], ascending=False)\n",
    "# Barplot erstellen\n",
    "sns.barplot(data=ratings, x=\"rating\", y='count', color='b', ax=ax, order=ratings['rating'])\n",
    "ax.set(xlabel='Bewertung', ylabel='Zahl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ae005",
   "metadata": {},
   "source": [
    "####  Meistverwendete Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc13a01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# WordCloud-Diagramm der am häufigsten verwendeten Wörter erstellen\n",
    "plt.figure(figsize=(15, 12), facecolor = None)\n",
    "plt.imshow(WordCloud(width = 800, height = 400,\n",
    "                     background_color='white').generate( full_caption_text ))\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.title('meistverwendete Wörter', fontsize=23, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ec6a9",
   "metadata": {},
   "source": [
    "#### Meistverwendete Nomen & Verben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39d207",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Erstellung meistverwendeten Nomen und Verben\n",
    "freqNoun = getWordFrequency(full_caption_text, \"NOUN\")\n",
    "freqVerb = getWordFrequency(full_caption_text, \"VERB\")\n",
    "\n",
    "# Erstellung der Variablen \"freqs\" und \"titles\", um die Häufigkeit von Nomen und Verben darzustellen.\n",
    "freqs = [freqNoun, freqVerb]\n",
    "titles = ['meistverwendete Nomen', 'meistverwendete Verben']\n",
    "\n",
    "# WordCloud-Diagramm mit 2 Subplots\n",
    "f, axes = plt.subplots(1,2)\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(20)\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(WordCloud(width = 800, height = 800,\n",
    "                        background_color='white').generate_from_frequencies( freqs[i] ))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titles[i], fontsize=18, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eac240",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funktionszuweisung - freq\n",
    "freq = getWordFrequency(full_caption_text, \"NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a78989",
   "metadata": {},
   "source": [
    "#### Meisteverwendete Verben pro Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f38ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Bewertungen der jeweiligen Sterne-Kategorien in String-Format joinen\n",
    "full_caption_text_1 = '. '.join(df.loc[df['rating'] == 1]['caption'])\n",
    "full_caption_text_2 = '. '.join(df.loc[df['rating'] == 2]['caption'])\n",
    "full_caption_text_3 = '. '.join(df.loc[df['rating'] == 3]['caption'])\n",
    "full_caption_text_4 = '. '.join(df.loc[df['rating'] == 4]['caption'])\n",
    "full_caption_text_5 = '. '.join(df.loc[df['rating'] == 5]['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e757c9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Berechnung der Häufigkeit von Adjektiven im Text mit 5 und 4 Sternen Bewertung\n",
    "freqs1 = [ getWordFrequency(full_caption_text_5, \"ADJ\"),\n",
    "           getWordFrequency(full_caption_text_4, \"ADJ\")]\n",
    "\n",
    "# Berechnung der Häufigkeit von Adjektiven im Text mit 3, 2 und 1 Sternen Bewertung\n",
    "freqs2 = [getWordFrequency(full_caption_text_3, \"ADJ\"),\n",
    "          getWordFrequency(full_caption_text_2, \"ADJ\"),\n",
    "          getWordFrequency(full_caption_text_1, \"ADJ\")]\n",
    "\n",
    "# Titel für das Wordcloud-Diagramm\n",
    "titles1 = ['5 Sterne', '4 Sterne']\n",
    "titles2 = ['3 Sterne', '2 Sterne', '1 Stern']\n",
    "\n",
    "# Erstellung von zwei Subplots mit einer Spalte und zwei bzw. drei Zeilen.\n",
    "f1, axes1 = plt.subplots(1, 2)\n",
    "f2, axes2 = plt.subplots(1, 3)\n",
    "\n",
    "# Plotgröße ändern\n",
    "f1.set_figheight(15)\n",
    "f1.set_figwidth(20)\n",
    "\n",
    "# Plotgröße ändern\n",
    "f2.set_figheight(15)\n",
    "f2.set_figwidth(20)\n",
    "\n",
    "# Erstellung der WordCloud-Diagramme für Texte mit 5 und 4 Sterne Bewertung\n",
    "for i, ax in enumerate(axes1):\n",
    "    ax.imshow(WordCloud(width = 300, height = 300,\n",
    "                        background_color='white').generate_from_frequencies( freqs1[i] ))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titles1[i], fontsize=18, fontweight='bold')\n",
    "\n",
    "# Erstellung der WordCloud-Diagramme für Texte mit 3, 2 und 1 Sterne Bewertung\n",
    "for i, ax in enumerate(axes2):\n",
    "    ax.imshow(WordCloud(width = 300, height = 300,\n",
    "                        background_color='white').generate_from_frequencies( freqs2[i] ))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titles2[i], fontsize=18, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f76a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db693bc",
   "metadata": {},
   "source": [
    "### 2.4 Modeling\n",
    "In der vierten Phase des CRISP-DM Modell, dem Modeling, werden verschiedene Modellierungstechniken evaluiert. Es wird überprüft, welche Technik für das jeweilige Data-Mining-Problem am besten anwendbar ist. Hier müssen gegebenenfalls die Schritte der Datenvorbereitung wiederholt werden. Neben der Auswahl der Modellierungstechnik und der eigentlichen Modellierung wird oder werden die Modelle am Ende dieser Phase ebenfalls nach verschiedenen Kriterien bewertet und in den Kontext des Data-Mining-Problems eingeordnet [1].\n",
    "\n",
    "Für die spätere Bewertung werden bei Klassifizierungsproblemen, wie dies, welches in diesem Projekt vorliegt, Fehlerraten als Qualitätsmaßstab genutzt. Um eine verzerrungsfreie Evaluierung sicherstellen zu können, müssen die Daten in ein Trainings- und einem Testdatensatz getrennt werden. Die Modellierung beruht dann auf dem Trainingsdatensatz und wird mithilfe des Testdatensatzes die Qualität der Vorhersage geschätzt [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d51917",
   "metadata": {},
   "source": [
    "#### 2.4.1 Erster Ansatz mit NLP-TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649366ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selbsterstellte Bewertungen mit Label\n",
    "trainingsdata = pd.read_csv(REVIEWS_CLEANED_FILE_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23eb9a",
   "metadata": {},
   "source": [
    "Die gesäuberten Daten wurden manuell mit den verschiedenen Kategorien gelabelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über die Daten\n",
    "trainingsdata.iloc[:,1:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40003df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren und Anwenden des Textklassifikationsmodells definieren\n",
    "def nlp_tfidfvectorizer(data, category, text):\n",
    "    \n",
    "    # Ausschnitt der Spalte \"caption\" und Funktions-Parameter\n",
    "    subset_train = data[['caption', category]]\n",
    "    # Ausschnitt in eine Liste von Tuples konventieren\n",
    "    train_data = list(subset_train.itertuples(index=False, name=None))\n",
    "    \n",
    "    # Trainingsdaten (Beispiele von Texten, die manuell in die verschiedenen Kategorien eingeteilt wurden)\n",
    "    training_data = train_data\n",
    "    \n",
    "    # Pipeline, die aus einem TfidfVectorizer und einem LinearSVC-Modell besteht\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('svc', LinearSVC())\n",
    "    ])\n",
    "\n",
    "    # Modell auf den Trainingsdaten trainieren\n",
    "    model.fit([text for text, category in training_data], [category for text, category in training_data])\n",
    "\n",
    "    # Vorhersage der Kategorie\n",
    "    predicted_category = model.predict([text])\n",
    "    \n",
    "    return predicted_category[0] if predicted_category else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cd4d1",
   "metadata": {},
   "source": [
    "In obiger Funktion wird eine Pipeline erstellt, die einen Text in ein maschinenlesbares Format umwandelt und dann eine lineare SVM verwendet, um die Textdaten zu klassifizieren. Die Intention dieser Funktion ist eine automatische Zuordnung von Texten zu bestimmten Kategorien auf der Grundlage eines trainierten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für die Kategorie Essen\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'food_positive', 'Das Essen war gut')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'food_positive', 'Es hat nicht geschmeckt')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'food_positive', 'Schlechtes Essen')}\")\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'food_positive', 'Es war köstlich')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'food_positive', 'Es war schlimm')}\")\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\nAccuracy: {3/5}%, jedoch Tendenz zur Vorhersage der Kategorie 1, da Overfitting der Trainingsdaten\\nEbenso wurden keine komplexen Satzstellung als Input verwendet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60108aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für die Kategorie Service\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'service_positive', 'Super freundlich')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'service_positive', 'Unfreundliche Bedienung')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'service_positive', 'Die Bedienung war sehr unfreundlich')}\")\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'service_positive', 'Die Bedienung war sehr freundlich')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'service_positive', 'Das Essen war sehr lecker, doch die Bedienung war nicht freundlich')}\")\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\nAccuracy: {4/5}%, jedoch nicht Aussagekräftig, da keine komplexen Satzstellungen als Input verwendet wurden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8352bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für die Kategorie Ambiente\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'ambient_positive', 'Schönes Ambiente')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'ambient_positive', 'Kein schönes Ambiente')}\")\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'ambient_positive', 'Das Ambiente war schön')}\")\n",
    "print(f\"Actually: 1, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'ambient_positive', 'Wir haben uns sehr wohl gefühlt')}\")\n",
    "print(f\"Actually: 0, Predictet: {nlp_tfidfvectorizer(trainingsdata, 'ambient_positive', 'Das Essen war sehr lecker, doch das Ambiente war nicht schön')}\")\n",
    "print(\"...\")\n",
    "\n",
    "print(f\"\\nAccuracy: {2/5}%, Anwendung komplexerer Satzstellungen --> Resultiert in schlechterer Genauigkeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759e18a",
   "metadata": {},
   "source": [
    "Es ist festzustellen, dass der Umfang des Trainingsdatensatzes zu gering ist um eine gute Vorhersage eines Textes zu erzeugen. Die Vorhersagen in den Unterschiedlichen Kategorien sind vielversprechend, wenn der Text aus wenigen Wörtern besteht und nicht Teil eines komplexen Satzes ist. Aufgrund dessen wird dieser Ansatz verworfen und im nächsten Abschnitt ein Model implementiert, welches die Bewertungen selbst labeln kann. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0a5f7",
   "metadata": {},
   "source": [
    "#### 2.4.2 Vorhersage der Bewertung\n",
    "Nachdem die gescrapten Bewertungen mithilfe des Models gelabelt wurden, dienen diese Daten nun als Trainingsdaten für eine multiple lineare Regression. \n",
    "\n",
    "Zur Vorhersage der Bewertung werden verschiedene Modelle getestet, darunter multiple-lineare Regression, Random-Forest-Regression und ein Textcat-Modell. Das am besten geeignete Modell wird ausgewählt, um die spezifischen Vorgaben zu erfüllen und eine Vorhersage über eine neue Bewertung zu treffen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf4f76",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Multiple lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c61663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe der maschinell gelabelten Daten einlesen\n",
    "labeld_data = pd.read_csv(REVIEWS_CLEANED_FILE_PATH, sep=';') # Gelabelte Daten von Textcat Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c79081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Spalte definieren\n",
    "data_predict = labeld_data.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prädiktoren und Zielvariable definieren\n",
    "X = data_predict.iloc[:, 2:]\n",
    "y = data_predict[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c040f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN-Werte mit 0 füllen\n",
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99268932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52042f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineare Regressionsmodell initialisieren\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5599fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model auf die Trainingsdaten fitten\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a962845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen treffen\n",
    "predicitions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eefe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cceb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe der gewünschten Kategorien und Vorhersage der neuen Bewertung\n",
    "# Anwender ist gutes Essen wichtig (Index 0 = 1)\n",
    "# Anwender ist guter Service egal (Index 2 = 0)\n",
    "# Anwender ist ein gutes Ambiente wichtig (Index 4 = 0)\n",
    "# Anwender ist ein angemessener Preis wichtig (Index 6 = 1)\n",
    "# Anwender ist eine lange Wartezeit egal (Index 8 = 0)\n",
    "neue_bewertung = model.predict(np.array([1, 0, 0, 0, 1, 0, 1, 0, 0, 0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Bewertung gemäß der gewünschten Kriterien\n",
    "print(f\"Die neue Bewertung beträgt: {round(neue_bewertung[0], 2)} Sterne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a141346",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cbcdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Erstellen des RandomForest-Regression-Modells mit 100 Bäumen\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34835f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Anpassen des Modells an die Trainingsdaten\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfddd19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Vorhersagen auf den Testdaten durchführen\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3891d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Berechnen der mittleren quadratischen Abweichung (MSE) des Modells\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9cc7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ausgabe des MSE des Modells\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2012e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Eingabe der gewünschten Kategorien und Vorhersage der neuen Bewertung\n",
    "# Anwender ist gutes Essen wichtig (Index 0 = 1)\n",
    "# Anwender ist guter Service egal (Index 2 = 0)\n",
    "# Anwender ist ein gutes Ambiente wichtig (Index 4 = 0)\n",
    "# Anwender ist ein angemessener Preis wichtig (Index 6 = 1)\n",
    "# Anwender ist eine lange Wartezeit egal (Index 8 = 0)\n",
    "vorhersage = rf.predict(np.array([1, 0, 0, 0, 1, 0, 1, 0, 0, 0]).reshape(1, -1))\n",
    "\n",
    "# Ausgabe der Vorhersage\n",
    "print(f\"Vorhersage: {round(vorhersage[0], 2)} Sterne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db0786",
   "metadata": {},
   "source": [
    "#### NLP-textcat_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194cefd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(REVIEWS_CLEANED_FILE_PATH, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6e4ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iteration durch jede Zeile des Dataframes\n",
    "for _, row in df.iterrows():\n",
    "    # Zuweisung der \"caption\"-Spalte der Variable text\n",
    "    text = row[\"caption\"]\n",
    "    # Zuweisung der \"rating\"-Spalte der Variable rating\n",
    "    rating = row[\"rating\"]\n",
    "\n",
    "    # Liste von Spaltennamen, die später als Kategorien verwendet werden sollen\n",
    "    target_columns = ['1', '2', '3', '4', '5']\n",
    "\n",
    "    # Doc-Object erstellen\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Iterieration durch jede Spalte in der target_columns-Liste\n",
    "    for column in target_columns:\n",
    "        # Überprüfung auf Übereinstimmung\n",
    "        doc.cats[column] = (rating == int(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb89391",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Objekt zur spacy-Pipeline hinzufügen\n",
    "textcat_multilabel = nlp.add_pipe(\"textcat_multilabel\", config={\n",
    "    \"threshold\": 0.5,\n",
    "    \"model\": DEFAULT_MULTI_TEXTCAT_MODEL,\n",
    "}, last=True)\n",
    "\n",
    "# alle 5 Labels hinzufügen\n",
    "for column in target_columns:\n",
    "    textcat_multilabel.add_label(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd9518",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['rating'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fceb2ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zur Aufteilung in Trainings- und Testsets\n",
    "def load_data(split=0.8):\n",
    "    # Index, an dem die Daten in Trainings- und Testsets aufgeteilt werden\n",
    "    split = int(len(df) * split)\n",
    "\n",
    "    X_train = df['caption'][:split]\n",
    "    y_train = df['rating'][:split]\n",
    "\n",
    "    X_test = df['caption'][split:]\n",
    "    y_test = df['rating'][split:]\n",
    "\n",
    "    # Gib die Trainings- und Testdaten als Tupel zurück\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4df22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Laden der Trainings- und Testdaten mithilfe der \"load_data\"-Funktion\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# X_train Kategorie Zuweisung\n",
    "train_data = list(zip(X_train, [{'cats': {\n",
    "    column: (int(column) == int(rating)) for column in target_columns\n",
    "}\n",
    "} for index, rating in enumerate(y_train)]))\n",
    "\n",
    "# X_test Kategorie Zuweisung\n",
    "test_data = list(zip(X_test, [{'cats': {\n",
    "    column: int(column) == int(rating) for column in target_columns\n",
    "}\n",
    "} for index, rating in enumerate(y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0000708",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e550e6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TextCategorizer trainieren\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat_multilabel']\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.initialize()\n",
    "    # Die Gewichte werden 100 Iterationen lang ständig aktualisiert.\n",
    "    for i in range(100): # Iterations\n",
    "        losses = {}\n",
    "        np.random.shuffle(train_data)\n",
    "        for batch in minibatch(train_data, size=8):\n",
    "            for text, annotations in batch:\n",
    "                # Example erstellen\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                # Das Modell aktualisieren\n",
    "                nlp.update([example], drop=0.3, sgd=optimizer, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66934aed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Die Bewertung des Models\n",
    "correct = 0\n",
    "total = 0\n",
    "accuracies = []\n",
    "\n",
    "for index, row in enumerate(test_data):\n",
    "    text = row[0]\n",
    "    annotations = row[1]\n",
    "\n",
    "    doc = nlp(text)\n",
    "    scores = textcat_multilabel.predict([doc])\n",
    "\n",
    "    item_accuracies = []\n",
    "    for i, key in enumerate(target_columns):\n",
    "        isSame = annotations['cats'][key] == round(scores[0][i])\n",
    "        item_accuracies.append(1 if isSame else 0)\n",
    "\n",
    "    score_item_accuracy = np.array(item_accuracies).sum() / len(target_columns)\n",
    "    accuracies.append(score_item_accuracy)\n",
    "\n",
    "accuracy = np.array(accuracies).sum() / len(accuracies)\n",
    "print(f\"Genauigkeit: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c62ad4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Die Staff sind super fruendliche und die Atmosphäre ist chillig. Es gibt eine Schöne Auswahl an Pizzas, die richtig lecker sind. Alles wird schnell fertig gemacht, ohne lange Wartezeit und ohne das die Qalität leidet.'\n",
    "prediction = textcat_multilabel.predict([nlp(text)])\n",
    "df_prediction = pd.DataFrame(prediction)\n",
    "df_prediction.columns = [1, 2, 3, 4, 5]\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad5a14",
   "metadata": {},
   "source": [
    "#### 2.4.3 Bewertung der Ergebnis\n",
    "Random Forest Regression ist besser für Daten mit nicht-linearen Zusammenhängen, Robustheit gegen Ausreißer und kann wichtige Variablen identifizieren, aber es ist schwierig zu interpretieren. Die direkte Vorhersage von Bewertungen anhand von Texten war für das Projekt ungeeignet, da das Ziel darin bestand, einen Zusammenhang der Bewertungen zu bestimmten Kategorien wie Qualität des Essens, Service und Preis-Leistungsverhältnis zu finden. Obwohl Random-Forest-Regression schwer zu interpretieren ist, bietet es die beste Vorhersage und die automatisierte Kategorisierung kann die Interpretierbarkeit des Modells verbessern. Multiple Lineare Regression ist bei nicht-linearen Zusammenhängen ungenau und fehleranfällig.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81f7aa",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832b1fe",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation\n",
    "Bei der Phase der Evaluation wird überprüft, ob die Zielsetzung des Data-Mining-Projekts erreicht wurde. Hierbei werden die Resultate der Modellierung und das Vorgehen bzw. der Prozess der Informationsgewinnung bewertet. Falls das Ergebnis hier deutlich negativ ausfällt, ist zu überprüfen, ob es gegebenenfalls einen erneuten Durchlauf des CRISP-DM-Modells benötigt. Zum Schluss werden die nächsten Schritte bzw. die Schritte für as Deployment festgelegt [1].\n",
    "\n",
    "HIER EVALUATION ÜBER MODELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb55dc",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c8159",
   "metadata": {},
   "source": [
    "### 2.6 Deployment\n",
    "Das Deployment kann über verschiedene Weg stattfinden. Ein anwenderfreundlicher Weg wäre z.B. der Zugriff über ein Streamlit-Dashboard.\n",
    "\n",
    "Hierbei kann der Anwender den Link zum Google-Maps Eintrag des gewünschten Restaurants zur Verfügung stellen und im Anschluss die Kriterien auswählen, die zur neu Berechnung der Bewertung genutzt werden sollen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7984a8",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ab170",
   "metadata": {},
   "source": [
    "## 3 Fazit\n",
    "Die Auswertung von Google Bewertungen gestaltete sich als äußerst schwierig, da die Texte sehr individuell und oft in Umgangssprache verfasst wurden. Die Erstellung geeigneter Trainingsdaten für eine automatische Analyse ist mit viel Aufwand verbunden. Die automatisierte Kategorisierung mit Spacy war die effektivste Methode, um große Mengen an Bewertungen schnell zu kategorisieren und manuelle Überprüfungen zu reduzieren. Die direkte Vorhersage von Bewertungen mithilfe von Textcat erwies sich ebenfalls als schwierig und erfordert tiefes Verständnis von Sprachstrukturen und Kontext. Das erstellte Modell auf Basis des automatisierten Labeling mithilfe von Matcher und TextBlob sowie die Vorhersage mittels Random-Forest-Regression erbrachte die besten Ergebnisse, ist jedoch bzgl. der Zuverlässigkeit der Vorhersagen mit befriedigend zu bewerten. \n",
    "\n",
    "<br> Die Analyse von Google Bewertungen ist eine komplexe Aufgabe, die viel Wissen und Erfahrung in der Sprachverarbeitung und Datenanalyse erfordert. Es müssen die Grenzen der Automatisierung berücksichtigt werden, und der Verzicht einer menschlichen Überprüfung, um genaue Ergebnisse zu erzielen, ist in diesem Projekt nicht gelungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee23c4",
   "metadata": {},
   "source": [
    "<img src=\"images/bar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d134f",
   "metadata": {},
   "source": [
    "## 4 Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb031e",
   "metadata": {},
   "source": [
    "[1] Shearer, C. (2000) The CRISP-DM Model: The New Blueprint for Data Mining. Journal of Data Warehousing, 5, 17.\n",
    "<br> [2] Marangon, J. (2022, 7. November), Building a Text Classification model with spaCy 3.x. Medium. Online-Vorveröffentlichung. https://medium.com/@johnidouglasmarangon/building-a-text-classification-model-with-spacy-3-x-57e59fa50547\n",
    "<br> [3] Mattingly, W. (2022), Topic Modeling: Concepts and Theory. Python Humanities. Online-Vorveröffentlichung. http://python-textbook.pythonhumanities.com/04_topic_modeling/04_01_01_intro.html\n",
    "<br> [4] Pattakos, A. (2021, 28. Februar), Aspect-Based Sentiment Analysis Using Spacy & TextBlob. Towards Data Science. Online-Vorveröffentlichung. https://towardsdatascience.com/aspect-based-sentiment-analysis-using-spacy-textblob-4c8de3e0d2b9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
